clc
clear all
clc
# comentar
clc
clear
clear all
isntall.packages("swirl")
install.packages("swirl")
library("swirl")
swirl()
5+7
x<-5+7
x
y<-x-3
y
# Cargamos la librería AER donde está alojada la data
library(pacman)
p_load(AER, tidyverse, caret, MLmetrics, tidymodels, themis)
# Importamos los datos
data("Affairs")
# Codificamos la variable de affairs según el diccionario
diccionario_affairs = c("Nunca", "Una vez", "Dos veces",
"Tres veces", "4 a 10 veces",
"Más de 10 veces")
# Codificamos la variable de affairs según el diccionario
diccionario_affairs = c("Nunca", "Una vez", "Dos veces",
"Tres veces", "4 a 10 veces",
"Más de 10 veces")
# Importamos los datos
data("Affairs")
Affairs$affairs <- factor(Affairs$affairs,
levels = c(0, 1, 2, 3, 7, 12),
labels = diccionario_affairs)
ggplot(Affairs, aes(x = affairs)) +
geom_bar(fill = "darkblue") +
theme_bw() +
labs(title = "¿Con qué frecuencia tuvo relaciones sexuales extramatrimoniales \n durante el último año?",
x = "",
y = "Frecuencia") +
coord_flip()
# crear variable infiel a partir de la variable categorica creada affairs
Affairs$infiel <- Affairs$affairs != "Nunca"
prop.table(table(Affairs$infiel))
# ver distribucion de la variable a predecir
prop.table(table(Affairs$infiel))
table(table(Affairs$infiel))
# ver distribucion de la variable a predecir
prop.table(table(Affairs$infiel))
# clasificación de desbalan
LogLikelihood <- function (y_pred, y_true) {
# Número cercano a cercano para evitar división por cero
eps <- 1e-15
# Si la probabilidad predicha es 0, agregale eps
# Si la probabilidad predicha es 1, restele eps
y_pred <- pmax(pmin(y_pred, 1 - eps), eps)
# Pasamos de booleano a numerico
y_true <- y_true + 0
LogLoss <- sum(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
return(LogLoss)
}
View(LogLikelihood)
LogLikelihood(y_true=1, y_pred = 1)
round(LogLikelihood(y_true=1, y_pred = 1))
y_hat <- seq(0.001, 0.999, length.out = 100)
l <- c()
for (i in 1:100) {
li <- LogLikelihood(y_pred = y_hat[i], y_true = 1)
l <- c(l, li)
}
y_hat_fiel <- rep(0,n)
y_hat_fiel <- rep(0,n)
# caso infieles: y_true=1
l <- c()
for (i in 1:100) {
li <- LogLikelihood(y_pred = y_hat[i], y_true = 1)
l <- c(l, li)
}
plot_f <- data.frame(y_hat = y_hat, log_likelihood = l)
ggplot(plot_f, aes(x = y_hat, y = log_likelihood)) +
geom_point() +
geom_line() +
geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
theme_bw() +
labs(x = "Valor predicho", y = "Log-verosimilitud")
# Log-verosimilitud cuando se dice que todas las personas son fieles
n <- nrow(Affairs)
y_hat_fieles <- rep(0, n)
l_fieles <- LogLikelihood(y_pred = y_hat_fieles, y_true = Affairs$infiel)
# Log-verosimilitud cuando todos son infieles
y_hat_infieles <- rep(1, n)
l_infieles <- LogLikelihood(y_pred = y_hat_infieles, y_true = Affairs$infiel)
# Log-verosimilitud cuando el 75% de las personas es fiel seleccionado al azar
y_hat_fieles75 <- c(rep(0, round(n*0.75, 0)), rep(1, round(n*0.25, 0)))
# Corremos 10000 simulaciones
set.seed(666)
l_fieles75 <- c()
for (i in 1:10000) {
y_hat_fieles75_i <- sample(y_hat_fieles75, n)
l_fieles75_i <- LogLikelihood(y_pred = y_hat_fieles75_i,
y_true = Affairs$infiel)
l_fieles75 <- c(l_fieles75, l_fieles75_i)
}
# Log-verosimilitud cuando el 100% de las predicciones es correcta
l_maximo <- LogLikelihood(y_pred = Affairs$infiel, y_true = Affairs$infiel)
ggplot() +
geom_histogram(aes(x = l_fieles75), fill = "darkblue") + theme_bw() +
geom_vline(aes(xintercept = l_fieles,
color = "100% Fieles"), linetype = "dashed") +
geom_vline(aes(xintercept = l_infieles,
color = "100% Infieles"), linetype = "dashed") +
geom_vline(aes(xintercept = l_maximo,
color = "Máxima Log-verosimilitud"),
linetype = "dashed") +
labs(x = "Log-verosimilitud", y = "Frecuencia") +
scale_color_manual(name = "Escenario",
values = c("100% Infieles" = "red",
"100% Fieles" = "blue",
"Máxima Log-verosimilitud" = "green"))
ggplot() +
geom_histogram(aes(x = l_fieles75), fill = "darkblue") + theme_bw() +
geom_vline(aes(xintercept = l_fieles,
color = "100% Fieles"), linetype = "dashed") +
geom_vline(aes(xintercept = l_infieles,
color = "100% Infieles"), linetype = "dashed") +
geom_vline(aes(xintercept = l_maximo,
color = "Máxima Log-verosimilitud"),
linetype = "dashed") +
labs(x = "Log-verosimilitud", y = "Frecuencia") +
scale_color_manual(name = "Escenario",
values = c("100% Infieles" = "red",
"100% Fieles" = "blue",
"Máxima Log-verosimilitud" = "green"))
LogLikelihood <- function (y_pred, y_true) {
# Número cercano a cercano para evitar división por cero
eps <- 1e-15
# Si la probabilidad predicha es 0, agregale eps
# Si la probabilidad predicha es 1, restele eps
y_pred <- pmax(pmin(y_pred, 1 - eps), eps)
# Pasamos de booleano a numerico
y_true <- y_true + 0
LogLoss <- sum(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
return(LogLoss)
}
plot_f <- data.frame(y_hat = y_hat, log_likelihood = l)
ggplot(plot_f, aes(x = y_hat, y = log_likelihood)) +
geom_point() +
geom_line() +
geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
theme_bw() +
labs(x = "Valor predicho", y = "Log-verosimilitud")
# Log-verosimilitud cuando se dice que todas las personas son fieles
n <- nrow(Affairs)
y_hat_fieles <- rep(0, n)
l_fieles <- LogLikelihood(y_pred = y_hat_fieles, y_true = Affairs$infiel)
# Log-verosimilitud cuando todos son infieles
y_hat_infieles <- rep(1, n)
l_infieles <- LogLikelihood(y_pred = y_hat_infieles, y_true = Affairs$infiel)
# Log-verosimilitud cuando el 75% de las personas es fiel seleccionado al azar
y_hat_fieles75 <- c(rep(0, round(n*0.75, 0)), rep(1, round(n*0.25, 0)))
# Corremos 10000 simulaciones
set.seed(666)
l_fieles75 <- c()
for (i in 1:10000) {
y_hat_fieles75_i <- sample(y_hat_fieles75, n)
l_fieles75_i <- LogLikelihood(y_pred = y_hat_fieles75_i,
y_true = Affairs$infiel)
l_fieles75 <- c(l_fieles75, l_fieles75_i)
}
L
# Log-verosimilitud cuando el 100% de las predicciones es correcta
l_maximo <- LogLikelihood(y_pred = Affairs$infiel, y_true = Affairs$infiel)
ggplot() +
geom_histogram(aes(x = l_fieles75), fill = "darkblue") + theme_bw() +
geom_vline(aes(xintercept = l_fieles,
color = "100% Fieles"), linetype = "dashed") +
geom_vline(aes(xintercept = l_infieles,
color = "100% Infieles"), linetype = "dashed") +
geom_vline(aes(xintercept = l_maximo,
color = "Máxima Log-verosimilitud"),
linetype = "dashed") +
labs(x = "Log-verosimilitud", y = "Frecuencia") +
scale_color_manual(name = "Escenario",
values = c("100% Infieles" = "red",
"100% Fieles" = "blue",
"Máxima Log-verosimilitud" = "green"))
Affairs$occupation <- factor(Affairs$occupation)
Affairs$education <- factor(Affairs$education)
Affairs$occupation <- factor(Affairs$occupation)
Affairs$education <- factor(Affairs$education)
Affairs$occupation <- factor(Affairs$occupation)
Affairs$education <- factor(Affairs$education)
# Dummyficamos ANTES de partir la base en train/test
# Creamos las variables edad y años de casados al cuadrado
df <- model.matrix(~ . + I(age^2) + I(yearsmarried^2) - affairs - 1, Affairs)
View(df)
View(df)
# Dividimos train/test (70/30)
smp_size <- floor(0.7*n)
# Dividimos train/test (70/30)
smp_size <- floor(0.7*n)
set.seed(666)
train_ind <- sample(1:n, size = smp_size)
# dividir la base con variables dummys entre train-set y test-set
smp_size <- floor(0.7*n)
set.seed(666)
train_ind <- sample(1:n, size = smp_size)
train <- df[train_ind, ]
test <- df[-train_ind, ]
# dividir la base con variables dummys entre train-set y test-set
smp_size <- floor(0.7*n)
set.seed(666)
train_ind <- sample(1:n, size = smp_size)
train <- df[train_ind, ]
test <- df[-train_ind, ]
# Estandarizamos DESPUÉS de partir la base en train/test
variables_numericas <- c("age", "yearsmarried", "religiousness",
"rating", "I(age^2)", "I(yearsmarried^2)")
# escalador de variables
escalador <- preProcess(train[, variables_numericas])
train_s <- train
test_s <- test
train_s[, variables_numericas] <- predict(escalador, train[, variables_numericas])
test_s[, variables_numericas] <- predict(escalador, test[, variables_numericas])
train_s <- data.frame(train_s)
test_s <- data.frame(test_s)
train <- data.frame(train)
test <- data.frame(test)
train_s <- data.frame(train_s)
test_s <- data.frame(test_s)
train <- data.frame(train)
test <- data.frame(test)
train_s$infielTRUE <- as.numeric(train_s$infielTRUE)
modelo1 <- lm(formula = infielTRUE ~ ., data = train_s)
probs_insample1 <- predict(modelo1, train_s)
probs_insample1[probs_insample1 < 0] <- 0
probs_insample1[probs_insample1 > 1] <- 1
probs_outsample1 <- predict(modelo1, test_s)
probs_outsample1[probs_outsample1 < 0] <- 0
probs_outsample1[probs_outsample1 > 1] <- 1
train_s <- data.frame(train_s)
test_s <- data.frame(test_s)
train <- data.frame(train)
test <- data.frame(test)
train_s$infielTRUE <- as.numeric(train_s$infielTRUE)
modelo1 <- lm(formula = infielTRUE ~ ., data = train_s)
probs_insample1 <- predict(modelo1, train_s)
probs_insample1[probs_insample1 < 0] <- 0
probs_insample1[probs_insample1 > 1] <- 1
probs_outsample1 <- predict(modelo1, test_s)
probs_outsample1[probs_outsample1 < 0] <- 0
probs_outsample1[probs_outsample1 > 1] <- 1
probs_insample1 <- predict(modelo1, train_s)
probs_insample1 <- predict(modelo1, train_s)
# truncar las predicciones
probs_insample1[probs_insample1 < 0] <- 0
probs_insample1[probs_insample1 > 1] <- 1
probs_insample1 <- predict(modelo1, train_s)
# truncar las predicciones
probs_insample1[probs_insample1 < 0] <- 0
probs_insample1[probs_insample1 > 1] <- 1
# predecir en el test-set
probs_outsample1 <- predict(modelo1, test_s)
probs_outsample1[probs_outsample1 < 0] <- 0
probs_outsample1[probs_outsample1 > 1] <- 1
# Convertimos la probabilidad en una predicción
y_hat_insample1 <- as.numeric(probs_insample1 > 0.5)
y_hat_outsample1 <- as.numeric(probs_outsample1 > 0.5)
acc_insample1 <- Accuracy(y_pred = y_hat_insample1, y_true = train$infielTRUE)
acc_outsample1 <- Accuracy(y_pred = y_hat_outsample1, y_true = test$infielTRUE)
pre_insample1 <- Precision(y_pred = y_hat_insample1, y_true = train$infielTRUE, positive = 1)
pre_outsample1 <- Precision(y_pred = y_hat_outsample1, y_true = test$infielTRUE, positive = 1)
rec_insample1 <- Recall(y_pred = y_hat_insample1, y_true = train$infielTRUE, positive = 1)
rec_outsample1 <- Recall(y_pred = y_hat_outsample1, y_true = test$infielTRUE, positive = 1)
f1_insample1 <- F1_Score(y_pred = y_hat_insample1, y_true = train$infielTRUE, positive = 1)
f1_outsample1 <- F1_Score(y_pred = y_hat_outsample1, y_true = test$infielTRUE, positive = 1)
# metricas de evaluación sobre el train-set
metricas_insample1 <- data.frame(Modelo = "Regresión lineal",
"Muestreo" = NA,
"Evaluación" = "Dentro de muestra",
"Accuracy" = acc_insample1,
"Precision" = pre_insample1,
"Recall" = rec_insample1,
"F1" = f1_insample1)
# metricas de evaluación sobre el test-st
metricas_outsample1 <- data.frame(Modelo = "Regresión lineal",
"Muestreo" = NA,
"Evaluación" = "Fuera de muestra",
"Accuracy" = acc_outsample1,
"Precision" = pre_outsample1,
"Recall" = rec_outsample1,
"F1" = f1_outsample1)
View(metricas_insample1)
View(metricas_insample1)
View(metricas_outsample1)
View(metricas_outsample1)
View(metricas_insample1)
View(metricas_insample1)
View(metricas_outsample1)
View(metricas_outsample1)
metricas1 <- bind_rows(metricas_insample1, metricas_outsample1)
metricas1 %>%
kbl(digits = 2)  %>%
kable_styling(full_width = T)
metricas4 <- bind_rows(metricas_insample4, metricas_outsample4)
# Dummyficamos ANTES de partir la base en train/test
# Creamos las variables edad y años de casados al cuadrado
df <- model.matrix(~ , Affairs)
# Cargamos la librería AER donde está alojada la data
library(pacman)
p_load(AER, tidyverse, caret, MLmetrics, tidymodels, themis)
# Importamos los datos
data("Affairs")
# Codificamos la variable de affairs según el diccionario
diccionario_affairs = c("Nunca", "Una vez", "Dos veces",
"Tres veces", "4 a 10 veces",
"Más de 10 veces")
# realizar pre procesamiento
Affairs$occupation <- factor(Affairs$occupation)
Affairs$education <- factor(Affairs$education)
# Creamos las variables edad y años de casados al cuadrado
df <- model.matrix(~ . + I(age^2) + I(yearsmarried^2) - affairs - 1, Affairs)
View(df)
# Cargamos la librería AER donde está alojada la data
library(pacman)
p_load(AER, tidyverse, caret, MLmetrics, tidymodels, themis)
# Importamos los datos
data("Affairs")
# Codificamos la variable de affairs según el diccionario
diccionario_affairs = c("Nunca", "Una vez", "Dos veces",
"Tres veces", "4 a 10 veces",
"Más de 10 veces")
# codificar variable affairs (número de infidelidades)
Affairs$affairs <- factor(Affairs$affairs,
levels = c(0, 1, 2, 3, 7, 12),
labels = diccionario_affairs)
# crear variable infiel a partir de la variable categorica creada affairs
Affairs$infiel <- Affairs$affairs != "Nunca"
# ver distribucion de la variable a predecir
prop.table(table(Affairs$infiel))
# codificar variable affairs (número de infidelidades)
Affairs$affairs <- factor(Affairs$affairs,
levels = c(0, 1, 2, 3, 7, 12),
labels = diccionario_affairs)
# codificar variable affairs (número de infidelidades)
Affairs$affairs <- factor(Affairs$affairs,
levels = c(0, 1, 2, 3, 7, 12),
labels = diccionario_affairs)
# crear grafico de barras
ggplot(Affairs, aes(x = affairs)) +
geom_bar(fill = "darkblue") +
theme_bw() +
labs(title = "¿Con qué frecuencia tuvo relaciones sexuales extramatrimoniales \n durante el último año?",
x = "",
y = "Frecuencia") +
coord_flip()
ggplot(Affairs, aes(x = affairs)) +
geom_bar(fill = "darkblue") +
theme_bw() +
labs(title = "¿Con qué frecuencia tuvo relaciones sexuales extramatrimoniales \n durante el último año?",
x = "",
y = "Frecuencia") +
coord_flip()
# Importamos los datos
data("Affairs")
# Codificamos la variable de affairs según el diccionario
diccionario_affairs = c("Nunca", "Una vez", "Dos veces",
"Tres veces", "4 a 10 veces",
"Más de 10 veces")
# realizar pre procesamiento
# crear dummys de variables
# hacer variables categorias
# estandarizar variables
# drop variables no significativas, con ruido
#
# codificar variable affairs (número de infidelidades)
Affairs$affairs <- factor(Affairs$affairs,
levels = c(0, 1, 2, 3, 7, 12),
labels = diccionario_affairs)
# crear variable infiel a partir de la variable categorica creada affairs
Affairs$infiel <- Affairs$affairs != "Nunca"
# ver distribucion de la variable a predecir
prop.table(table(Affairs$infiel))
LogLikelihood <- function (y_pred, y_true) {
# Número cercano a cercano para evitar división por cero
eps <- 1e-15
# Si la probabilidad predicha es 0, agregale eps
# Si la probabilidad predicha es 1, restele eps
y_pred <- pmax(pmin(y_pred, 1 - eps), eps)
# Pasamos de booleano a numerico
y_true <- y_true + 0
LogLoss <- sum(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
return(LogLoss)
}
# caso1: fieles
y_hat_fiel <- rep(0,n)
y_hat <- seq(0.001, 0.999, length.out = 100)
# caso infieles: y_true=1
l <- c()
for (i in 1:100) {
li <- LogLikelihood(y_pred = y_hat[i], y_true = 1)
l <- c(l, li)
}
plot_f <- data.frame(y_hat = y_hat, log_likelihood = l)
ggplot(plot_f, aes(x = y_hat, y = log_likelihood)) +
geom_point() +
geom_line() +
geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
theme_bw() +
labs(x = "Valor predicho", y = "Log-verosimilitud")
# Log-verosimilitud cuando se dice que todas las personas son fieles
n <- nrow(Affairs)
y_hat_fieles <- rep(0, n)
l_fieles <- LogLikelihood(y_pred = y_hat_fieles, y_true = Affairs$infiel)
# Log-verosimilitud cuando se dice que todas las personas son fieles
n <- nrow(Affairs)
y_hat_fieles <- rep(0, n)
l_fieles <- LogLikelihood(y_pred = y_hat_fieles, y_true = Affairs$infiel)
# Log-verosimilitud cuando todos son infieles
y_hat_infieles <- rep(1, n)
l_infieles <- LogLikelihood(y_pred = y_hat_infieles, y_true = Affairs$infiel)
# Log-verosimilitud cuando el 75% de las personas es fiel seleccionado al azar
y_hat_fieles75 <- c(rep(0, round(n*0.75, 0)), rep(1, round(n*0.25, 0)))
# Corremos 10000 simulaciones
set.seed(666)
l_fieles75 <- c()
for (i in 1:10000) {
y_hat_fieles75_i <- sample(y_hat_fieles75, n)
l_fieles75_i <- LogLikelihood(y_pred = y_hat_fieles75_i,
y_true = Affairs$infiel)
l_fieles75 <- c(l_fieles75, l_fieles75_i)
}
# Log-verosimilitud cuando el 100% de las predicciones es correcta
l_maximo <- LogLikelihood(y_pred = Affairs$infiel, y_true = Affairs$infiel)
ggplot() +
geom_histogram(aes(x = l_fieles75), fill = "darkblue") + theme_bw() +
geom_vline(aes(xintercept = l_fieles,
color = "100% Fieles"), linetype = "dashed") +
geom_vline(aes(xintercept = l_infieles,
color = "100% Infieles"), linetype = "dashed") +
geom_vline(aes(xintercept = l_maximo,
color = "Máxima Log-verosimilitud"),
linetype = "dashed") +
labs(x = "Log-verosimilitud", y = "Frecuencia") +
scale_color_manual(name = "Escenario",
values = c("100% Infieles" = "red",
"100% Fieles" = "blue",
"Máxima Log-verosimilitud" = "green"))
# Pre-procesamiento de datos
Affairs$occupation <- factor(Affairs$occupation)
Affairs$education <- factor(Affairs$education)
View(Affairs)
View(Affairs)
# Dummyficamos ANTES de partir la base en train/test
# Creamos las variables edad y años de casados al cuadrado
df <- model.matrix(~ . + I(age^2) + I(yearsmarried^2) - affairs - 1, Affairs)
View(df)
View(df)
# dividir la base con variables dummys entre train-set y test-set
smp_size <- floor(0.7*n)
# dividir la base con variables dummys entre train-set y test-set
smp_size <- floor(0.7*n)
set.seed(666)
train_ind <- sample(1:n, size = smp_size)
train <- df[train_ind, ]
test <- df[-train_ind, ]
# dividir la base con variables dummys entre train-set y test-set
smp_size <- floor(0.8*n)
set.seed(666)
train_ind <- sample(1:n, size = smp_size)
train <- df[train_ind, ]
test <- df[-train_ind, ]
# Estandarizamos DESPUÉS de partir la base en train/test
variables_numericas <- c("age", "yearsmarried", "religiousness",
"rating", "I(age^2)", "I(yearsmarried^2)")
variables_numericas
escalador <- preProcess(train[, variables_numericas])
train_s <- train
test_s <- test
train_s[, variables_numericas] <- predict(escalador, train[, variables_numericas])
test_s[, variables_numericas] <- predict(escalador, test[, variables_numericas])
train_s <- data.frame(train_s)
test_s <- data.frame(test_s)
train <- data.frame(train)
test <- data.frame(test)
View(train_s)
train_s$infielTRUE <- as.numeric(train_s$infielTRUE)
modelo1 <- lm(formula = infielTRUE ~ ., data = train_s)
modelo1.summary()
summary(modelo1)
source("~/GitHub/BD-ML---PS3/scripts/diego/base.R")
source("~/GitHub/BD-ML---PS3/scripts/diego/base.R")
